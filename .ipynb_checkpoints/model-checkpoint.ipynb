{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090f5e43-5a24-4c7a-9b3d-1e8aaf718e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.12.5\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 1.26.4 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.9.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 1.5.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 2.2.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m xgboost version 2.1.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m shap version 0.45.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m plotly version 5.23.0 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from packaging.version import parse as Version\n",
    "from platform import python_version\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.12 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == Version(min_ver):\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(python_version())\n",
    "\n",
    "if pyversion >= Version(\"3.12.5\"):\n",
    "    print(OK, \"Python version is %s\" % pyversion)\n",
    "elif pyversion < Version(\"3.12.5\"):\n",
    "    print(FAIL, \"Python version 3.12.5 is required,\"\n",
    "                \" but %s is installed.\" % pyversion)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % pyversion)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"1.26.4\", 'matplotlib': \"3.9.2\",'sklearn': \"1.5.1\", \n",
    "                'pandas': \"2.2.2\",'xgboost': \"2.1.1\", 'shap': \"0.45.1\", \n",
    "                'plotly': \"5.23.0\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5bb811-b07b-48e2-a754-788d3621b01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id full_name   age      gender device_type ad_position  \\\n",
      "0      670   User670  22.0         NaN     Desktop         Top   \n",
      "1     3044  User3044   NaN        Male     Desktop         Top   \n",
      "2     5912  User5912  41.0  Non-Binary         NaN        Side   \n",
      "3     5418  User5418  34.0        Male         NaN         NaN   \n",
      "4     9452  User9452  39.0  Non-Binary         NaN         NaN   \n",
      "...    ...       ...   ...         ...         ...         ...   \n",
      "9995  8510  User8510   NaN         NaN      Mobile         Top   \n",
      "9996  7843  User7843   NaN      Female     Desktop      Bottom   \n",
      "9997  3914  User3914   NaN        Male      Mobile        Side   \n",
      "9998  7924  User7924   NaN         NaN     Desktop         NaN   \n",
      "9999  3056  User3056  44.0        Male      Tablet         Top   \n",
      "\n",
      "     browsing_history time_of_day  click  \n",
      "0            Shopping   Afternoon      1  \n",
      "1                 NaN         NaN      1  \n",
      "2           Education       Night      1  \n",
      "3       Entertainment     Evening      1  \n",
      "4        Social Media     Morning      0  \n",
      "...               ...         ...    ...  \n",
      "9995        Education         NaN      0  \n",
      "9996    Entertainment         NaN      0  \n",
      "9997              NaN     Morning      0  \n",
      "9998         Shopping     Morning      1  \n",
      "9999     Social Media     Morning      0  \n",
      "\n",
      "[10000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/ad_click_dataset.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b5639e-17b3-4529-9168-460a4441055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: (2019, 6) (2019,)\n",
      "\n",
      "Training set size: (6385, 6) (6385,)\n",
      "Validation set size: (1596, 6) (1596,)\n",
      "Training set size: (6383, 6) (6383,)\n",
      "Validation set size: (1598, 6) (1598,)\n",
      "Training set size: (6384, 6) (6384,)\n",
      "Validation set size: (1597, 6) (1597,)\n",
      "Training set size: (6386, 6) (6386,)\n",
      "Validation set size: (1595, 6) (1595,)\n",
      "Training set size: (6386, 6) (6386,)\n",
      "Validation set size: (1595, 6) (1595,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit, StratifiedGroupKFold\n",
    "\n",
    "X = df.drop(columns=['click', 'id', 'full_name']) #Dropping full name, as it adds no value\n",
    "y = df['click']  #Target variable\n",
    "groups = df['id'] \n",
    "\n",
    "def group_split_with_stratifiedGroupkfold(X, y, groups, train_size, test_size, n_splits, random_state):\n",
    "    if train_size + test_size != 1:\n",
    "        raise ValueError('The sum of the train_size and test_size should be 1.')\n",
    "    \n",
    "    #Using GroupShuffleSplit to split into train+validation and test set\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    for i_train_val, i_test in splitter.split(X, y, groups):\n",
    "        X_train_val, y_train_val, groups_train_val = X.iloc[i_train_val], y.iloc[i_train_val], groups.iloc[i_train_val]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    \n",
    "    print('Test set size:', X_test.shape, y_test.shape)\n",
    "    print()\n",
    "    \n",
    "    #Using Stratified GroupKFold to split the train+validation set into train and validation sets\n",
    "    skf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    for i_train, i_val in skf.split(X_train_val, y_train_val, groups_train_val):\n",
    "        X_train, y_train, groups_train = X_train_val.iloc[i_train], y_train_val.iloc[i_train], groups_train_val.iloc[i_train]\n",
    "        X_val, y_val, groups_val = X_train_val.iloc[i_val], y_train_val.iloc[i_val], groups_train_val.iloc[i_val]\n",
    "    \n",
    "        print('Training set size:', X_train.shape, y_train.shape) \n",
    "        print('Validation set size:', X_val.shape, y_val.shape)\n",
    "        \n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "random_state = 42\n",
    "n_splits = 5  #Number of folds for GroupKFold\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = group_split_with_stratifiedGroupkfold(X, y, groups, train_size=0.8, test_size=0.2, n_splits=n_splits, random_state=random_state)\n",
    "\n",
    "#print(X_train.head())\n",
    "#print(X_val.head())\n",
    "#print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a96409-aa8c-4638-b0c8-0288068fa16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6386, 6)\n",
      "(6386, 24)\n",
      "(1595, 6)\n",
      "(1595, 24)\n",
      "(2019, 6)\n",
      "(2019, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "cat_ftrs = ['gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day']\n",
    "num_ftrs = ['age']\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)]) \n",
    "\n",
    "X_train_prep = clf.fit_transform(X_train)\n",
    "X_val_prep = clf.transform(X_val)\n",
    "X_test_prep = clf.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_prep.shape)\n",
    "#print(X_train_prep)\n",
    "\n",
    "print(X_val.shape)\n",
    "print(X_val_prep.shape)\n",
    "#print(X_val_prep)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test.shape)\n",
    "#print(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940bd1e-c9b1-4ab0-b940-c3637f01f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid, KFold\n",
    "import pickle\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.03],\n",
    "    \"n_estimators\": [10000],\n",
    "    \"missing\": [np.nan],\n",
    "    \"colsample_bytree\": [0.9],\n",
    "    \"subsample\": [0.66],\n",
    "    \"reg_alpha\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    \"reg_lambda\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    \"max_depth\": [1, 3, 10, 30, 100]\n",
    "}\n",
    "pg = ParameterGrid(param_grid)\n",
    "\n",
    "results = {\n",
    "    'test_rmse': [],\n",
    "    'test_accuracy': [],\n",
    "    'test_precision': [],\n",
    "    'test_recall': [],\n",
    "    'test_f1': []\n",
    "}\n",
    "\n",
    "random_states = [2, 7, 4, 9, 3]\n",
    "\n",
    "for random_state in random_states:\n",
    "    print(f\"\\nRandom State {random_state}...\")\n",
    "\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_val_transformed = preprocessor.transform(X_val)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    scores = []\n",
    "    for params in pg:\n",
    "        fold_rmse = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X_train_transformed):\n",
    "            X_cv_train, X_cv_val = X_train_transformed[train_idx], X_train_transformed[val_idx]\n",
    "            y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            model = xgb.XGBClassifier(\n",
    "                **params, random_state=random_state, eval_metric='logloss',\n",
    "                n_jobs=-1, early_stopping_rounds=50\n",
    "            )\n",
    "            model.fit(\n",
    "                X_cv_train, y_cv_train,\n",
    "                eval_set=[(X_cv_val, y_cv_val)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            y_cv_pred = model.predict(X_cv_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_cv_val, y_cv_pred))\n",
    "            fold_rmse.append(rmse)\n",
    "\n",
    "        cv_mean_rmse = np.mean(fold_rmse)\n",
    "        scores.append(cv_mean_rmse)\n",
    "\n",
    "    best_idx = np.argmin(scores)\n",
    "    best_params = list(pg)[best_idx]\n",
    "    print(f\"Best parameters after CV: {best_params}\")\n",
    "\n",
    "    best_model = xgb.XGBClassifier(\n",
    "        **best_params, random_state=random_state, eval_metric='logloss',\n",
    "        n_jobs=-1, early_stopping_rounds=50\n",
    "    )\n",
    "    best_model.fit(\n",
    "        X_train_transformed, y_train,\n",
    "        eval_set=[(X_val_transformed, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    y_test_pred = best_model.predict(X_test_transformed)\n",
    "\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "\n",
    "    results['test_rmse'].append(test_rmse)\n",
    "    results['test_accuracy'].append(test_acc)\n",
    "    results['test_precision'].append(test_precision)\n",
    "    results['test_recall'].append(test_recall)\n",
    "    results['test_f1'].append(test_f1)\n",
    "\n",
    "    # Print the metrics for this random state\n",
    "    print(f\"Best Params for Random State {random_state}: {best_params}\")\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "# Summary metrics\n",
    "mean_rmse = np.mean(results['test_rmse'])\n",
    "std_rmse = np.std(results['test_rmse'])\n",
    "mean_accuracy = np.mean(results['test_accuracy'])\n",
    "std_accuracy = np.std(results['test_accuracy'])\n",
    "mean_precision = np.mean(results['test_precision'])\n",
    "std_precision = np.std(results['test_precision'])\n",
    "mean_recall = np.mean(results['test_recall'])\n",
    "std_recall = np.std(results['test_recall'])\n",
    "mean_f1 = np.mean(results['test_f1'])\n",
    "std_f1 = np.std(results['test_f1'])\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Test RMSE: {mean_rmse:.4f} +/- {std_rmse:.4f}\")\n",
    "print(f\"Test Accuracy: {mean_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {mean_precision:.4f} +/- {std_precision:.4f}\")\n",
    "print(f\"Test Recall: {mean_recall:.4f} +/- {std_recall:.4f}\")\n",
    "print(f\"Test F1-Score: {mean_f1:.4f} +/- {std_f1:.4f}\")\n",
    "\n",
    "\n",
    "with open(\"results.pkl\", \"wb\") as file:\n",
    "    pickle.dump(results, file)\n",
    "\n",
    "print(\"Results have been saved to results.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e4c542-58fa-458e-829d-484ff7ae1b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1]) \n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(f\"Confusion Matrix for XGB\")\n",
    "plt.savefig('model1.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead0f5de-9332-4b33-804e-d72412c175a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global\n",
    "import shap\n",
    "\n",
    "df_test = pd.DataFrame(X_test_transformed, columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "explainer = shap.TreeExplainer(XGB)  \n",
    "shap_values = explainer.shap_values(df_test)  \n",
    "\n",
    "mean_shap_values = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "top_10_indices = np.argsort(mean_shap_values)[-10:]\n",
    "top_10_features = df_test.columns[top_10_indices]\n",
    "top_10_importances = mean_shap_values[top_10_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10_features[::-1], top_10_importances[::-1]) \n",
    "plt.xlabel('Mean |SHAP Value|')\n",
    "plt.title('Top 10 Features by SHAP Importance')\n",
    "plt.savefig('model2.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf958232-ef0b-4328-b344-24152ec69b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "feature_names = np.array(feature_names)\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    XGB,\n",
    "    df_test, \n",
    "    y_test,         \n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "importances = perm_importance.importances_mean\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "top_10_indices = sorted_indices[:10]\n",
    "top_10_features = feature_names[top_10_indices]\n",
    "top_10_importances = importances[top_10_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(10), top_10_importances[::-1], align=\"center\", color=\"skyblue\")\n",
    "plt.yticks(range(10), top_10_features[::-1])\n",
    "plt.xlabel(\"Mean Permutation Importance\")\n",
    "plt.title(\"Top 10 Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('model3.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc485e-ee4e-461f-8710-209f5da42cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb 5 metrics\n",
    "\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "feature_mapping = {f\"f{i}\": name for i, name in enumerate(feature_names)}\n",
    "\n",
    "importance_types = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "feature_importances = {}\n",
    "\n",
    "for i in importance_types:\n",
    "    raw_importances = XGB.get_booster().get_score(importance_type=i)\n",
    "    feature_importances[i] = {feature_mapping.get(k, k): v for k, v in raw_importances.items()}\n",
    "\n",
    "def get_sorted_importance(importance_dict):\n",
    "    sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    features, scores = zip(*sorted_importance)\n",
    "    return features, scores\n",
    "\n",
    "for i in importance_types:\n",
    "    features, scores = get_sorted_importance(feature_importances[i])\n",
    "    top_10_features = features[:10]\n",
    "    top_10_scores = scores[:10]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top_10_features[::-1], top_10_scores[::-1])  \n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'Top 10 Features by {i.capitalize()}')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('model4.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f06e3c-5354-4a0d-bc35-d765c7bf0c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local\n",
    "shap.initjs()\n",
    "\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "explainer = shap.TreeExplainer(XGB)\n",
    "\n",
    "index = 0  \n",
    "shap_values = explainer.shap_values(df_test) \n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values[index],\n",
    "    features=df_test.iloc[index],\n",
    "    feature_names=feature_names \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72963e1-a8bf-4dc3-9836-2bde31bb0edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(XGB)\n",
    "\n",
    "index = 100  \n",
    "shap_values = explainer.shap_values(df_test) \n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values[index],\n",
    "    features=df_test.iloc[index],\n",
    "    feature_names=feature_names \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5129e68-7181-4df9-833f-8d31e4600b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(XGB)\n",
    "\n",
    "index = 200  \n",
    "shap_values = explainer.shap_values(df_test) \n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values[index],\n",
    "    features=df_test.iloc[index],\n",
    "    feature_names=feature_names \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65cae15-f75c-4ee9-8860-aa9b8da5fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b9670b-c509-4fde-b826-7c2351addc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ad_click_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b401619-7dca-485c-8406-aa122bee8163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: (2019, 6) (2019,)\n",
      "Training set size: (6385, 6) (6385,)\n",
      "Validation set size: (1596, 6) (1596,)\n",
      "Training set size: (6383, 6) (6383,)\n",
      "Validation set size: (1598, 6) (1598,)\n",
      "Training set size: (6384, 6) (6384,)\n",
      "Validation set size: (1597, 6) (1597,)\n",
      "Training set size: (6386, 6) (6386,)\n",
      "Validation set size: (1595, 6) (1595,)\n",
      "Training set size: (6386, 6) (6386,)\n",
      "Validation set size: (1595, 6) (1595,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = df.drop(columns=['click', 'id', 'full_name']) #Dropping full name, as it adds no value\n",
    "y = df['click']  #Target variable\n",
    "groups = df['id'] \n",
    "\n",
    "def group_split_with_stratifiedGroupkfold(X, y, groups, train_size, test_size, n_splits, random_state):\n",
    "    if train_size + test_size != 1:\n",
    "        raise ValueError('The sum of the train_size and test_size should be 1.')\n",
    "    \n",
    "    #Using GroupShuffleSplit to split into train+validation and test set\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    for i_train_val, i_test in splitter.split(X, y, groups):\n",
    "        X_train_val, y_train_val, groups_train_val = X.iloc[i_train_val], y.iloc[i_train_val], groups.iloc[i_train_val]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    \n",
    "    print('Test set size:', X_test.shape, y_test.shape)\n",
    "    \n",
    "    #Using Stratified GroupKFold to split the train+validation set into train and validation sets\n",
    "    skf = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    for i_train, i_val in skf.split(X_train_val, y_train_val, groups_train_val):\n",
    "        X_train, y_train, groups_train = X_train_val.iloc[i_train], y_train_val.iloc[i_train], groups_train_val.iloc[i_train]\n",
    "        X_val, y_val, groups_val = X_train_val.iloc[i_val], y_train_val.iloc[i_val], groups_train_val.iloc[i_val]\n",
    "    \n",
    "        print('Training set size:', X_train.shape, y_train.shape) \n",
    "        print('Validation set size:', X_val.shape, y_val.shape)\n",
    "        \n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "random_state = 42\n",
    "n_splits = 5  #Number of folds for GroupKFold\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = group_split_with_stratifiedGroupkfold(X, y, groups, train_size=0.8, test_size=0.2, n_splits=n_splits, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90101b93-45ea-4084-b415-7848873069a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 64 unique missing value patterns.\n",
      "Processing pattern 1\n",
      "   Pattern 1: Train size (517, 19), Test size (142, 19)\n",
      "Processing pattern 2\n",
      "   Pattern 2: Train size (628, 15), Test size (34, 15)\n",
      "Processing pattern 3\n",
      "   Pattern 3: Train size (909, 14), Test size (142, 14)\n",
      "Processing pattern 4\n",
      "   Pattern 4: Train size (1118, 10), Test size (44, 10)\n",
      "Processing pattern 5\n",
      "   Pattern 5: Train size (636, 16), Test size (37, 16)\n",
      "Processing pattern 6\n",
      "   Pattern 6: Train size (783, 12), Test size (3, 12)\n",
      "Processing pattern 7\n",
      "   Pattern 7: Train size (1128, 11), Test size (38, 11)\n",
      "Processing pattern 8\n",
      "   Pattern 8: Train size (1404, 7), Test size (11, 7)\n",
      "Processing pattern 9\n",
      "   Pattern 9: Train size (623, 16), Test size (32, 16)\n",
      "Processing pattern 10\n",
      "   Pattern 10: Train size (762, 12), Test size (7, 12)\n",
      "Processing pattern 11\n",
      "   Pattern 11: Train size (1110, 11), Test size (36, 11)\n",
      "Processing pattern 12\n",
      "   Pattern 12: Train size (1366, 7), Test size (6, 7)\n",
      "Processing pattern 13\n",
      "   Pattern 13: Train size (770, 13), Test size (11, 13)\n",
      "Processing pattern 14\n",
      "   Pattern 14: Train size (958, 9), Test size (1, 9)\n",
      "Processing pattern 15\n",
      "   Pattern 15: Train size (1381, 8), Test size (8, 8)\n",
      "Processing pattern 16\n",
      "   Pattern 16: Train size (1725, 4), Test size (1, 4)\n",
      "Processing pattern 17\n",
      "   Pattern 17: Train size (933, 16), Test size (140, 16)\n",
      "Processing pattern 18\n",
      "   Pattern 18: Train size (1159, 12), Test size (31, 12)\n",
      "Processing pattern 19\n",
      "   Pattern 19: Train size (1727, 11), Test size (132, 11)\n",
      "Processing pattern 20\n",
      "   Pattern 20: Train size (2153, 7), Test size (31, 7)\n",
      "Processing pattern 21\n",
      "   Pattern 21: Train size (1138, 13), Test size (26, 13)\n",
      "Processing pattern 22\n",
      "   Pattern 22: Train size (1434, 9), Test size (7, 9)\n",
      "Processing pattern 23\n",
      "   Pattern 23: Train size (2119, 8), Test size (40, 8)\n",
      "Processing pattern 24\n",
      "   Pattern 24: Train size (2673, 4), Test size (9, 4)\n",
      "Processing pattern 25\n",
      "   Pattern 25: Train size (1133, 13), Test size (28, 13)\n",
      "Processing pattern 26\n",
      "   Pattern 26: Train size (1410, 9), Test size (8, 9)\n",
      "Processing pattern 27\n",
      "   Pattern 27: Train size (2121, 8), Test size (25, 8)\n",
      "Processing pattern 28\n",
      "   Pattern 28: Train size (2646, 4), Test size (4, 4)\n",
      "Processing pattern 29\n",
      "   Pattern 29: Train size (1399, 10), Test size (12, 10)\n",
      "Processing pattern 30\n",
      "   Pattern 30: Train size (1766, 6), Test size (2, 6)\n",
      "Processing pattern 31\n",
      "   Pattern 31: Train size (2635, 5), Test size (9, 5)\n",
      "Processing pattern 32\n",
      "   Pattern 32: Train size (3324, 1), Test size (3, 1)\n",
      "Processing pattern 33\n",
      "   Pattern 33: Train size (951, 18), Test size (143, 18)\n",
      "Processing pattern 34\n",
      "   Pattern 34: Train size (1167, 14), Test size (35, 14)\n",
      "Processing pattern 35\n",
      "   Pattern 35: Train size (1737, 13), Test size (136, 13)\n",
      "Processing pattern 36\n",
      "   Pattern 36: Train size (2140, 9), Test size (35, 9)\n",
      "Processing pattern 37\n",
      "   Pattern 37: Train size (1184, 15), Test size (26, 15)\n",
      "Processing pattern 38\n",
      "   Pattern 38: Train size (1468, 11), Test size (6, 11)\n",
      "Processing pattern 39\n",
      "   Pattern 39: Train size (2191, 10), Test size (32, 10)\n",
      "Processing pattern 40\n",
      "   Pattern 40: Train size (2724, 6), Test size (11, 6)\n",
      "Processing pattern 41\n",
      "   Pattern 41: Train size (1169, 15), Test size (30, 15)\n",
      "Processing pattern 42\n",
      "   Pattern 42: Train size (1434, 11), Test size (11, 11)\n",
      "Processing pattern 43\n",
      "   Pattern 43: Train size (2162, 10), Test size (34, 10)\n",
      "Processing pattern 44\n",
      "   Pattern 44: Train size (2660, 6), Test size (9, 6)\n",
      "Processing pattern 45\n",
      "   Pattern 45: Train size (1452, 12), Test size (12, 12)\n",
      "Processing pattern 46\n",
      "   Pattern 46: Train size (1807, 8), Test size (1, 8)\n",
      "Processing pattern 47\n",
      "   Pattern 47: Train size (2717, 7), Test size (9, 7)\n",
      "Processing pattern 48\n",
      "   Pattern 48: Train size (3380, 3), Test size (1, 3)\n",
      "Processing pattern 49\n",
      "   Pattern 49: Train size (1719, 15), Test size (105, 15)\n",
      "Processing pattern 50\n",
      "   Pattern 50: Train size (2135, 11), Test size (31, 11)\n",
      "Processing pattern 51\n",
      "   Pattern 51: Train size (3286, 10), Test size (90, 10)\n",
      "Processing pattern 52\n",
      "   Pattern 52: Train size (4085, 6), Test size (31, 6)\n",
      "Processing pattern 53\n",
      "   Pattern 53: Train size (2113, 12), Test size (32, 12)\n",
      "Processing pattern 54\n",
      "   Pattern 54: Train size (2649, 8), Test size (3, 8)\n",
      "Processing pattern 55\n",
      "   Pattern 55: Train size (4074, 7), Test size (26, 7)\n",
      "Processing pattern 56\n",
      "   Pattern 56: Train size (5112, 3), Test size (1, 3)\n",
      "Processing pattern 57\n",
      "   Pattern 57: Train size (2133, 12), Test size (38, 12)\n",
      "Processing pattern 58\n",
      "   Pattern 58: Train size (2649, 8), Test size (7, 8)\n",
      "Processing pattern 59\n",
      "   Pattern 59: Train size (4090, 7), Test size (29, 7)\n",
      "Processing pattern 60\n",
      "   Pattern 60: Train size (5084, 3), Test size (9, 3)\n",
      "Processing pattern 61\n",
      "   Pattern 61: Train size (2632, 9), Test size (11, 9)\n",
      "Processing pattern 62\n",
      "   Pattern 62: Train size (3302, 5), Test size (1, 5)\n",
      "Processing pattern 63\n",
      "   Pattern 63: Train size (5093, 4), Test size (13, 4)\n",
      "Processing pattern 64\n",
      "   Pattern 64 skipped (0 features remaining).\n",
      "Total subsets created: 63\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def preprocess_reduced_features(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    mask = X_test.isnull()\n",
    "    unique_rows = np.array(np.unique(mask, axis=0))\n",
    "    all_subsets = []\n",
    "\n",
    "    print(f'There are {len(unique_rows)} unique missing value patterns.')\n",
    "\n",
    "    for i, pattern in enumerate(unique_rows):\n",
    "        print(f'Processing pattern {i + 1}')\n",
    "\n",
    "        sub_X_test = X_test.loc[(mask == pattern).all(axis=1), :]\n",
    "        sub_y_test = y_test.loc[sub_X_test.index]\n",
    "\n",
    "        sub_X_train = X_train.loc[:, ~pattern]\n",
    "        sub_X_val = X_val.loc[:, ~pattern]\n",
    "        sub_X_train = sub_X_train.dropna()\n",
    "        sub_X_val = sub_X_val.dropna()\n",
    "\n",
    "        sub_y_train = y_train.loc[sub_X_train.index]\n",
    "        sub_y_val = y_val.loc[sub_X_val.index]\n",
    "\n",
    "        # Dynamically updating preprocessor for reduced features\n",
    "        cat_ftrs_dynamic = [col for col in cat_ftrs if col in sub_X_train.columns]\n",
    "        num_ftrs_dynamic = [col for col in num_ftrs if col in sub_X_train.columns]\n",
    "\n",
    "        # Skip if no features are left\n",
    "        if not cat_ftrs_dynamic and not num_ftrs_dynamic:\n",
    "            print(f\"   Pattern {i + 1} skipped (0 features remaining).\")\n",
    "            continue\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, num_ftrs_dynamic),\n",
    "                ('cat', categorical_transformer, cat_ftrs_dynamic)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        sub_X_train_prep = preprocessor.fit_transform(sub_X_train)\n",
    "        sub_X_val_prep = preprocessor.transform(sub_X_val)\n",
    "        sub_X_test_prep = preprocessor.transform(sub_X_test.loc[:, ~pattern])\n",
    "\n",
    "        # Ensuring preprocessed data has at least 1 feature\n",
    "        if sub_X_train_prep.shape[1] == 0:\n",
    "            print(f\"   Pattern {i + 1} skipped (0 features after preprocessing).\")\n",
    "            continue\n",
    "\n",
    "        all_subsets.append({\n",
    "            'pattern': i + 1,\n",
    "            'X_train_prep': sub_X_train_prep,\n",
    "            'y_train': sub_y_train,\n",
    "            'X_val_prep': sub_X_val_prep,\n",
    "            'y_val': sub_y_val,\n",
    "            'X_test_prep': sub_X_test_prep,\n",
    "            'y_test': sub_y_test\n",
    "        })\n",
    "\n",
    "        print(f'   Pattern {i + 1}: Train size {sub_X_train_prep.shape}, Test size {sub_X_test_prep.shape}')\n",
    "\n",
    "    return all_subsets\n",
    "\n",
    "reduced_datasets = preprocess_reduced_features(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "print(f'Total subsets created: {len(reduced_datasets)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d7ec22-91b1-452a-ab52-0b2a73b16e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Lasso across all missing patterns and random states...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m random_states \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Evaluate models on reduced datasets\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mMLpipe_multiple_random_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_datasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReduced Features Model Evaluation Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<15\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Test RMSE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>18\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStd Test RMSE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>18\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m, in \u001b[0;36mMLpipe_multiple_random_states\u001b[0;34m(reduced_datasets, models, param_grids, random_states)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m across all missing patterns and random states...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m model_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation RMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest RMSE\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Models\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     25\u001b[0m }\n\u001b[0;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_states\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mRandom State: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrandom_state\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Added for clarity\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduced_datasets\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def MLpipe_multiple_random_states(reduced_datasets, models, param_grids, random_states):\n",
    "    overall_results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name} across all missing patterns and random states...\")\n",
    "\n",
    "        model_results = {\n",
    "            'Validation RMSE': [],\n",
    "            'Test RMSE': [],\n",
    "            'Accuracy': [],\n",
    "            'Precision': [],\n",
    "            'Recall': [],\n",
    "            'F1-Score': [],\n",
    "            'Best Models': []\n",
    "        }\n",
    "\n",
    "        for random_state in random_states:\n",
    "            print(f\"\\nRandom State: {random_state}...\") \n",
    "            for subset in reduced_datasets:\n",
    "                X_train = subset['X_train_prep']\n",
    "                y_train = subset['y_train']\n",
    "                X_val = subset['X_val_prep']\n",
    "                y_val = subset['y_val']\n",
    "                X_test = subset['X_test_prep']\n",
    "                y_test = subset['y_test']\n",
    "\n",
    "                kfold = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "                grid_search = GridSearchCV(\n",
    "                    estimator=model,\n",
    "                    param_grid=param_grids[model_name],\n",
    "                    scoring='neg_root_mean_squared_error',\n",
    "                    cv=kfold,\n",
    "                )\n",
    "                \n",
    "                grid_search.fit(X_train, y_train)\n",
    "                best_model = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_  \n",
    "\n",
    "                \n",
    "                print(f\"Best Params for {model_name} (Random State {random_state}): {best_params}\")\n",
    "\n",
    "                y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "            \n",
    "                if np.issubdtype(y_test_pred.dtype, np.floating):\n",
    "                    y_test_pred = (y_test_pred >= 0.5).astype(int)\n",
    "\n",
    "                test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "                model_results['Test RMSE'].append(test_rmse)\n",
    "\n",
    "                accuracy = accuracy_score(y_test, y_test_pred)\n",
    "                precision = precision_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "                recall = recall_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "                f1 = f1_score(y_test, y_test_pred, average='weighted', zero_division=0)\n",
    "\n",
    "                model_results['Accuracy'].append(accuracy)\n",
    "                model_results['Precision'].append(precision)\n",
    "                model_results['Recall'].append(recall)\n",
    "                model_results['F1-Score'].append(f1)\n",
    "\n",
    "                model_results['Best Models'].append(best_model)\n",
    "\n",
    "        overall_results[model_name] = {\n",
    "            'Mean Test RMSE': np.mean(model_results['Test RMSE']),\n",
    "            'Std Test RMSE': np.std(model_results['Test RMSE']),\n",
    "            'Mean Accuracy': np.mean(model_results['Accuracy']),\n",
    "            'Mean Precision': np.mean(model_results['Precision']),\n",
    "            'Mean Recall': np.mean(model_results['Recall']),\n",
    "            'Mean F1-Score': np.mean(model_results['F1-Score']),\n",
    "            'Std F1-Score': np.std(model_results['F1-Score']),  \n",
    "            'Best Models': model_results['Best Models']\n",
    "        }\n",
    "\n",
    "        # Print overall metrics for the current model\n",
    "        print(f\"{model_name} - Mean Test RMSE: {np.mean(model_results['Test RMSE']):.4f}, \"\n",
    "              f\"Std Test RMSE: {np.std(model_results['Test RMSE']):.4f}\")\n",
    "        print(f\"{model_name} - Mean Accuracy: {np.mean(model_results['Accuracy']):.4f}, \"\n",
    "              f\"Mean Precision: {np.mean(model_results['Precision']):.4f}, \"\n",
    "              f\"Mean Recall: {np.mean(model_results['Recall']):.4f}, \"\n",
    "              f\"Mean F1-Score: {np.mean(model_results['F1-Score']):.4f}, \"\n",
    "              f\"Std F1-Score: {np.std(model_results['F1-Score']):.4f}\\n\") \n",
    "\n",
    "    return overall_results\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Lasso': Lasso(max_iter=10000),\n",
    "    'Ridge': Ridge(max_iter=10000),\n",
    "    'ElasticNet': ElasticNet(max_iter=10000),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'KNeighbors': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Lasso': {'alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
    "    'Ridge': {'alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
    "    'ElasticNet': {'alpha': [0.001, 0.01, 0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.9]},\n",
    "    'RandomForest': {'n_estimators': [1, 3, 10, 30], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    "    'KNeighbors': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance']}\n",
    "}\n",
    "\n",
    "random_states = [2, 7, 4, 9, 3]\n",
    "\n",
    "# Evaluating models on reduced datasets\n",
    "results = MLpipe_multiple_random_states(reduced_datasets, models, param_grids, random_state)\n",
    "\n",
    "print(\"\\nReduced Features Model Evaluation Summary:\")\n",
    "print(f\"{'Model':<15}{'Mean Test RMSE':>18}{'Std Test RMSE':>18}\")\n",
    "print(\"-\" * 51)\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    mean_test_rmse = result.get('Mean Test RMSE', 'N/A')\n",
    "    std_test_rmse = result.get('Std Test RMSE', 'N/A')\n",
    "    print(f\"{model_name:<15}{mean_test_rmse:>18.4f}{std_test_rmse:>18.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7030a2b-24dc-4508-a985-4fe1bb82549b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
